---
title: Second Post
date: 2024-07-07 17:00:00 +0900
categories: [Blogging, Data]
tags: [crawling] #소문자만
published: true
---

# 웹 크롤링  

### 정의
- **Wep(거미줄) + Crawling(기어가다)**
- 웹사이트에 있는 정보를 자동으로 빠르게 수집하는 것   

### 목적
- 데이터 수집 
- 웹사이트 자동화
- 인공지능 학습 데이터

### 활용
- 상품, 컨텐츠 자동 업로드
- 부동산 주식 재테크 데이터 수집
- 인스타그램, 유튜브 모니터링 및 분석
- 뉴스 데이터 수집
- 논문, 구인공고 데이터 수집
--- 

> ## 웹 페이지는 어떻게 볼 수 있을까?
### HTTP 통신
  - 웹 브라우저와 웹 서버 사이에 데이터를 주고 받는데 사용되는 통신
  - 웹 브라우저: 크롬,  엣지, 사파리
  - 웹 서버: 웹사이트에 대한 정보 제공
- 컴퓨터가 주소를 통해 페이지를 요청(**URL주소**)하면 서버가 응답(**HTML**)로 요청
- 크롤링을 하기 위해서 HTML에 대해 알 필요가 있음
  


### HTML(Hyper Text Markup Language)
  
- 웹사이트의 구조를 표시하기 위한 언어로, 페이지에 대한 정보가 들어 있음  

- #### 태그 
  
  ***<태그이름 속성="속성값"> 내용 </태그이름>***

   - 속성: 태그의 추가적인 정보, 여러개 부여 가능, 생략가능
   - 내용: 텍스트나 태그가 들어 갈 수 있음, 생략 가능

- HTML 기본 예제

   ``` HTML

   <!DOCTYPE html> <!-- 웹브라우저에게 HTML5로 작성함을 명시-->
   <html>
      <head>
         <body>
               <!-- 문서의 잡다한 정보-->
               <title> 스타트핏: 운동의 시작</title>
         </body>
               <!-- 화면에 표시되는 내용-->
               <h1> <!-- 소제목-->
                  스타트핏: 운동의시작
               </h1>
               <div> <!--구역나누는 태그-->
                  <h1>기초 체력업! 무분할 루틴</h1>
                  <p> <!-- 문단 나타내는 태그-->
                     운동을 처음 시작하는 헬린이 모여
                  </p> 
                  <a href="https://www.naver.com">지금 시작하기</a>
               </div>

               <div> <!--구역나누는 태그-->
                  <h1>초보탈출! 3분할 루틴</h1>
                  <p>운동좀 했니? 드루와</p> 
                  <a href="https://www.naver.com">지금 시작하기</a>
               </div>
               <div>
                  <h1>나만의 운동 목표 설정</h1>
                  <input type="text" placeholder="목표입력">
                  <button onclick="alert('레츠기릿!')">저장하기</button>
                  <ul>
                     <li><a href="#">웨이트로 몸짱되기!</a></li>
                     <li><a href="#">유산소 다이어트!</a></li>
                     <li><a href="#">필라테스로 유연성과 코어잡기!</a></li>
                  </ul>
               </div>
      </head>
   </html>
   ```
- 실행결과  
   ![HTML실행결과](/img/20240707/HTML실행결과.jpg)

### CSS
- #### 구문
    **: h1{color:red;}**

- **선택자(selector)**
  - **h1**에 해당
  - 웹페이지에서 원하는 태그를 선택하는 문법
- 종류  
  1) **태그 선택자**: 태그 이름으로 선택하는 것으로 다른 선택자와 합쳐져 많이 사용
  2) **클래스 선택자**: 클래스 속성값으로 선택
  3) **아이디 선택자**: 아이디 속성값으로 선택
  4) **자식 선택자**: 바로 아래 자식태그를 선택것, 내가 원하는 태그에 별명이 없을 때 사용 
- 선택자 사용 연습 사이트: https://flukeout.github.io/ 

- CSS 기본 예제
   ``` html
   <!DOCTYPE html> <!-- 웹브라우저에게 HTML5로 작성함을 명시-->
   <html>
      <head>
         <body>
               <!-- 문서의 잡다한 정보-->
               <title> 스타트핏: 운동의 시작</title>
               <style>
                  #main_title { color: orange;}
                  .sub_title{font-size: 24px;}
                  .box{background-color: steelblue; padding:15px; margin-bottom:20px; border-radius: 5px;}
                  .box > a{color: white;}
                  .box > p{color: lightblue;}
               </style>
         </body>
               <!-- 화면에 표시되는 내용-->
               <h1 id="main_title"> <!-- 소제목-->
                  스타트핏: 운동의시작
               </h1>
               <div class="box"> <!--구역나누는 태그-->
                  <h1 class="sub_title">기초 체력업! 무분할 루틴</h1>
                  <p> <!-- 문단 나타내는 태그-->
                     운동을 처음 시작하는 헬린이 모여
                  </p>  class="sub_title"
                  <a href="https://www.naver.com">지금 시작하기</a>
               </div>

               <div class="box"> <!--구역나누는 태그-->
                  <h1 class="sub_title">초보탈출! 3분할 루틴</h1>
                  <p>운동좀 했니? 드루와</p> 
                  <a href="https://www.naver.com">지금 시작하기</a>
               </div>
               <div class="box">
                  <h1 class="sub_title">나만의 운동 목표 설정</h1>
                  <input type="text" placeholder="목표입력">
                  <button onclick="alert('레츠기릿!')">저장하기</button>
                  <ul>
                     <li><a href="#">웨이트로 몸짱되기!</a></li>
                     <li><a href="#">유산소 다이어트!</a></li>
                     <li><a href="#">필라테스로 유연성과 코어잡기!</a></li>
                  </ul>
               </div>
      </head>
   </html>
   ```
- 실행결과  
   ![HTML실행결과](/img/20240707/CSS실행결과.jpg)

   --- 
> ## 정적 페이지(static page) 크롤링
- 정적 페이지
  - 데이터의 추가적인 변경이 일어나지 않는 페이지
  - 응답받은 HTML에 원하는 정보가 들어있음 -> 쉬움
- 동적 페이지
  - 데이터의 추가적인 변경이 일어나는 페이지
  - 응답받은 HTML에 원하는 정보가 들어있지 않음 -> **셀레니움 활용**

### 정적페이지 크롤링 방법
**1. 데이터 받아오기**
- 파이썬에서 서버에 요청을 보내고 응답받기
- URL요청 ->  HTML 수신

**2. 데이터 뽑아내기**
- HTML에서 원하는 부분만 추출
- CSS 선택자를 잘 만드는 것이 핵심
- BeautifullSoup4 라이브러리 사용 


### 기본 코드
``` python
# 크롤링 연습 사이트: https://startcoding.pythonanywhere.com/basic

import requests
from bs4 import BeautifulSoup

response=requests.get("https://startcoding.pythonanywhere.com/basic") # 응답 신호 저장할 객체 response
response.status_code # 통신이 성공적이라면 200 출력, 페이지 없다면 404출력 

response.text # HTML 문서 문자열 형태로 받아옴 -> 문자열 추출 힘들기 때문에 beautifulsowp 라이브러리 사용


response=requests.get("https://startcoding.pythonanywhere.com/basic") # 응답 신호 저장할 객체 response
html=response.text
soup=BeautifulSoup(html,'html.parser') # 문자열 형태의 html을 html.paser가 태그 객체로 하나씩 나눠서 soup에 담음
soup.select_one(".brand-name")
soup.select_one(".brand-name").text
soup.select_one(".brand-name").attrs
soup.select_one(".brand-name").attrs['href']

```

### 실습
- 한개의 상품 크롤링
- 여러개의 상품 크롤링
- 여러 페이지 크롤링
- 데이터 엑셀에 저장

>### step1) 상품 한개 크롤링

``` python
import requests
from bs4 import BeautifulSoup


response=requests.get("https://startcoding.pythonanywhere.com/basic") # 응답 신호 저장 객체 -> response
html=response.text
soup=BeautifulSoup(html,'html.parser') # 문자열 형태의 html을 html.paser가 태그 객체로 하나씩 나눠서 soup에 담음

soup.select_one(".brand-name")

# 1. 카테고리추출
category=soup.select_one(".product-category").text # select_one: 매칭되는 태그들 중 첫번째 가져옴

# 2. 상품명 추출
# 방법1 클래스 선택자 사용
name=soup.select_one(".product-name").text

# 방법2 자식 선택자 사용(text 사용시 1과 동일)
link=soup.select_one(".product-name > a").attrs['href']

# 3. 가격 추출 
price=soup.select_one(".product-price").text.strip().replace(',','').replace('원','') # 앞뒤 공백 제거 strip, 숫자만 남기기

print(category,name,link,price)
```
--- 

>### step2) 여러개의 상품 크롤링
### 포레스트 이론
  - 숲: 페이지 전체 HTML
  - 나무: 원하는 정보를 모두 담는 태그

### - 단계  
***1. 숲에서 원하는 정보를 모두 담는 나무 찾기***  
***2. CSS선택자를 만들어서 테스트***  
***3. soup.select("CSS선택자")로 숲에서 나무들 뽑기***  
***4. 반복문을 돌면서 나무에서 하나씩 열매 추출***

### - 나무 태그 찾는법  
  ***1.태그 하나를 찾는다***  
***2. 상위태그(부모태그)를 찾아 올라간다***  
***3. 원하는 정보를 모두 담고 있는지 확인한다***  

``` python
import requests
from bs4 import BeautifulSoup

response=requests.get("https://startcoding.pythonanywhere.com/basic") # 응답 신호 저장할 객체 response
html=response.text
soup=BeautifulSoup(html,'html.parser') # 문자열 형태의 html을 html.paser가 태그 객체로 하나씩 나눠서 soup에 담음

items=soup.select(".product") # 하나가 아닌 전부 가져옴 -> 리스트 형태

for item in items:
    category=item.select_one(".product-category").text # select_one: 매칭되는 태그들 중 첫번째 가져옴
    name=item.select_one(".product-name").text
    link=item.select_one(".product-name > a").attrs['href']
    price=item.select_one(".product-price").text.strip().split('원')[0].replace(',',"") # 앞뒤 공백 제거 strip
    print(category,name,link,price)

```
--- 
    
>### step3)  여러 페이지 크롤링
###  URL
- Uniform Resource Locator
- 인터넷 주소 형식
- ***Protocol - Domain - Path - Parameter 구성***  
![인터넷링크](https://www.beusable.net/blog/wp-content/uploads/2021/02/image-7.png)

### 페이징 알고리즘 단계  
   ***1. 페이지를 바꾸면서 URL이 변경되는 부분을 찾는다 (value값이 없는 파라미터라면 삭제해도 됨)***  
   ***2. 페이지를 증가시키면서 요청을 보낸다***  

```python
import requests
from bs4 import BeautifulSoup


for i in range(1,5):
    response=requests.get(f"https://startcoding.pythonanywhere.com/basic?page={i}") # 응답 신호 저장할 객체 response
    html=response.text
    soup=BeautifulSoup(html,'html.parser') # 문자열 형태의 html을 html.paser가 태그 객체로 하나씩 나눠서 soup에 담음
    items=soup.select(".product") # 하나가 아닌 전부 가져옴 -> 리스트 형태

    for item in items:
        category=item.select_one(".product-category").text # select_one: 매칭되는 태그들 중 첫번째 가져옴
        name=item.select_one(".product-name").text
        link=item.select_one(".product-name > a").attrs['href']
        price=item.select_one(".product-price").text.strip().split('원')[0].replace(',',"") # 앞뒤 공백 제거 strip
        print(category,name,link,price)

```
--- 

>### step4) 데이터 엑셀에 저장하는 법


***1.비어있는 리스트 생성 및 한행씩 추가***  
***2. 데이터 프레임을 만들고 엑셀에 저장, 판다스 사용***  
***3. 엑셀에 저장***
```python 
# pandas, openpyxl 설치

import requests
import pandas as pd
from bs4 import BeautifulSoup

data=[]
for i in range(1,5):
    response=requests.get(f"https://startcoding.pythonanywhere.com/basic?page={i}") # 응답 신호 저장할 객체 response
    html=response.text
    soup=BeautifulSoup(html,'html.parser') # 문자열 형태의 html을 html.paser가 태그 객체로 하나씩 나눠서 soup에 담음
    items=soup.select(".product") # 하나가 아닌 전부 가져옴 -> 리스트 형태

    for item in items:
        category=item.select_one(".product-category").text # select_one: 매칭되는 태그들 중 첫번째 가져옴
        name=item.select_one(".product-name").text
        link=item.select_one(".product-name > a").attrs['href']
        price=item.select_one(".product-price").text.strip().split('원')[0].replace(',',"") # 앞뒤 공백 제거 strip
        print(category,name,link,price)
        data.append([category,name,link,price])

# 데이터 프레임 만들기
df=pd.DataFrame(data,columns=['카테고리','상품명','링크',' 가격'])
df

# 엑셀 저장
df.to_excel('result.xlsx',index=False)
```
---
###  향후 배울 것
- 동적 페이지 크롤링
  - 셀레니움 
- 정적 페이지 크롤링
  - 기존 엑셀 파일에 추가하는 법
  - 엑셀 시트별로 저장하는 법
  